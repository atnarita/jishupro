{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wA7UFI__ICO"
   },
   "source": [
    "## 各種ライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1608180171807,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "s7bR7rBV_ICO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1608180172153,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "G2T5mDug_ICQ",
    "outputId": "610de4bc-7113-43fc-8fb2-64cf90018b9e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 90)\n",
      "[[ 0.     0.134  0.089 ...  2.405  3.608 -7.84 ]\n",
      " [ 2.405  3.564 -7.885 ...  2.405  3.653 -7.751]\n",
      " [ 2.45   3.608 -7.795 ...  2.45   3.564 -7.662]\n",
      " ...\n",
      " [ 8.33   0.624  0.178 ... -0.267  1.203  0.089]\n",
      " [-0.223  1.559 -0.49  ... -4.187  5.657 -7.484]\n",
      " [ 0.757  6.593  0.045 ...  0.223  1.069  2.539]]\n",
      "(265,)\n",
      "[0.  2.9 4.4 2.1 2.2 1.9 2.3 3.6 0.  2.6 2.4 2.3 2.  3.2 1.6 2.8 2.2 4.5\n",
      " 5.  1.6 1.9 1.4 2.3 1.1 1.1 2.  2.5 3.  1.  0.  0.2 0.7 1.1 2.  2.8 1.9\n",
      " 3.9 2.6 2.5 0.5 1.2 2.  3.  1.9 1.8 1.6 0.2 0.  0.  2.2 2.4 1.  2.  3.\n",
      " 1.7 2.5 1.4 1.4 2.6 2.  2.8 2.8 2.2 4.8 0.  2.1 0.  1.  2.6 2.4 2.1 2.\n",
      " 2.8 2.7 1.5 1.9 1.3 3.  2.9 2.3 2.4 2.5 0.  0.1 1.2 4.  4.  1.9 2.  1.8\n",
      " 3.1 1.5 0.  2.8 2.1 2.5 1.2 1.5 1.5 2.3 2.2 0.  0.  3.3 1.7 0.  0.6 0.9\n",
      " 1.8 1.  1.1 1.5 1.3 1.  1.2 1.1 1.4 1.9 1.  1.6 1.6 2.2 1.8 2.  2.4 2.7\n",
      " 2.1 3.9 4.2 4.9 3.8 3.2 3.1 1.2 2.2 2.7 1.3 1.6 1.  0.2 1.  1.9 2.2 3.4\n",
      " 2.3 0.8 1.1 1.6 3.8 1.7 1.1 2.6 3.4 0.8 1.  3.4 3.6 1.1 1.3 2.3 2.4 0.6\n",
      " 0.  0.  0.  0.  2.4 3.1 0.  0.  0.  1.1 2.3 2.3 2.3 0.9 1.2 1.  0.3 0.3\n",
      " 0.5 0.8 1.9 2.9 2.5 0.7 1.7 3.2 1.1 0.3 1.6 2.  3.3 3.2 3.2 0.  0.  0.\n",
      " 1.2 0.  0.6 1.8 2.8 4.9 4.1 1.2 2.2 3.2 2.1 3.  1.6 2.3 3.4 2.  2.8 0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  3.  3.3 1.5 0.  3.2 1.3 0.8 0.  0.  2.8\n",
      " 2.7 2.2 2.1 3.6 0.  0.9 0.  0.  0.  0.4 1.7 1.6 2.3 3.  2.7 1.  0.3 0.\n",
      " 0.7 4.6 1.9 2.5 2.9 0.  0.  2.  1.3 2.3 2.5 0.  1.8]\n"
     ]
    }
   ],
   "source": [
    "# データをロード\n",
    "training_acc = np.array(np.loadtxt('data/training_acc.txt', dtype='float64'))\n",
    "training_dis = np.array(np.loadtxt('data/training_dis.txt', dtype='float64'))\n",
    "\n",
    "print(training_acc.shape)\n",
    "print(training_acc)\n",
    "print(training_dis.shape)\n",
    "print(training_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdPRHaRx_ICS"
   },
   "source": [
    "## 活性化関数の定義\n",
    "### sigmoid, softmax, tanh関数とそれらの微分を宣言している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1608180174687,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "VhDYrLwp_ICS"
   },
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "# derivative of sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# softmax function\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# derivative of softmax function\n",
    "def softmax_prime(x):\n",
    "    return softmax(x) * (1 - softmax(x))\n",
    "\n",
    "# tanh function\n",
    "def tanh(x):\n",
    "  return (np.exp(x)-np.exp(-x)) / (np.exp(x)+np.exp(-x))\n",
    "\n",
    "def tanh_prime(x):\n",
    "  return 4 / (np.exp(x)+np.exp(-x))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gORmMiMT_ICS"
   },
   "source": [
    "## Layerの定義\n",
    "### 初期層、中間層、出力層でクラスが分けられているが全てにおいて、<br>layer = *_layer(入力次元数, 出力次元数, 学習率（指定しないと0.03）)のように宣言する。<br>逆伝播、順伝播の場合はそれぞれlayer.forward(...)、layer.backward(...)のようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1608180226031,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "VacjdgkN_ICT"
   },
   "outputs": [],
   "source": [
    "# ######################################最初の層についてのクラス###########################################\n",
    "# class start_layer(object):\n",
    "#     # initation\n",
    "#     def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "#         self.input_dim = input_dim # 入力次元\n",
    "#         self.output_dim = output_dim #出力次元\n",
    "#         self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "#         self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float64) #重みを決定\n",
    "#         self.bias = np.zeros((1, output_dim), dtype=np.float64) #バイアス項\n",
    "        \n",
    "#     # 順伝播\n",
    "#     def forward(self,x):\n",
    "#         # x_h ... input_dim次元の(縦)ベクトル\n",
    "#         self.input_x = np.array(x).reshape(self.input_dim)\n",
    "        \n",
    "#         # u_i ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim) \n",
    "        \n",
    "#         # x_i ... output_dim次元の(縦)ベクトルを出力 (sigmoidを作用させる)\n",
    "#         self.output_x = sigmoid(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "#         # u_i が 出力\n",
    "#         return self.output_u\n",
    "    \n",
    "#     # 逆伝播\n",
    "#     def backward(self,delta):# delta = δ_i\n",
    "#         # W = W - η .* (δ_i * x_h.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "#         self.weight = self.weight - self.learning_rate * np.dot(delta.reshape(self.output_dim,1), self.input_x.reshape(1, self.input_dim))\n",
    "#         return\n",
    "#  #################################################################################################\n",
    "\n",
    "\n",
    "# ######################################  中間層についてのクラス  ###########################################\n",
    "# class mid_layer(object):\n",
    "#     # initation\n",
    "#     def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "#         self.input_dim = input_dim # 入力次元\n",
    "#         self.output_dim = output_dim #出力次元\n",
    "#         self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "#         self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float64) #重みを決定\n",
    "#         self.bias = np.zeros((1, output_dim), dtype=np.float64) #バイアス項\n",
    "        \n",
    "#     # 順伝播   \n",
    "#     def forward(self,u):# u = u_i\n",
    "        \n",
    "#         # u_i ... input_dim次元の(縦)ベクトル\n",
    "#         self.input_u = np.array(u).reshape(self.input_dim)\n",
    "        \n",
    "#         # x_i ... input_dim次元の(縦)ベクトル\n",
    "#         self.input_x = sigmoid(self.input_u).reshape(self.input_dim) \n",
    "        \n",
    "#         # u_j ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim)\n",
    "        \n",
    "#         # x_j ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.output_x = sigmoid(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "#         # u_j が 出力\n",
    "#         return self.output_u\n",
    "    \n",
    "#     # 逆伝播\n",
    "#     def backward(self, delta):# delta = δ_j\n",
    "        \n",
    "#         # W = W - η .* (δ_j * x_i.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "#         self.weight = self.weight - self.learning_rate * np.dot(delta.reshape(self.output_dim,1), self.input_x.reshape(1, self.input_dim))\n",
    "        \n",
    "#         # δ_i = (W_ji.T *  δ_j) .* f'(u_i) ... input_dim次元の(縦)ベクトル\n",
    "#         return (np.dot(self.weight.T, delta) * sigmoid_prime(self.input_u)).reshape(self.input_dim)\n",
    "# #################################################################################################\n",
    "\n",
    "    \n",
    "# ######################################  中間層についてのクラス  ###########################################    \n",
    "# class last_layer(object):\n",
    "    \n",
    "#     def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "#         self.input_dim = input_dim # 入力次元\n",
    "#         self.output_dim = output_dim#出力次元\n",
    "#         self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "#         self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float64) #重みを決定\n",
    "#         self.bias = np.zeros((1, output_dim), dtype=np.float64) #バイアス項\n",
    "        \n",
    "#     # 順伝播    \n",
    "#     def forward(self,u):# u = u_j\n",
    "        \n",
    "#         # u_j ... input_dim次元の(縦)ベクトル\n",
    "#         self.input_u = np.array(u).reshape(self.input_dim) \n",
    "        \n",
    "#         # x_j ... input_dim次元の(縦)ベクトル\n",
    "#         self.input_x = sigmoid(self.input_u).reshape(self.input_dim)\n",
    "        \n",
    "#         # u_k ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim)\n",
    "        \n",
    "#         # x_k ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.output_x = softmax(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "#         # x_k が最終結果\n",
    "#         return self.output_x\n",
    "    \n",
    "#     # 逆伝播\n",
    "#     def backward(self,loss):# loss = y - y^p\n",
    "        \n",
    "#         # δ_k = loss * f'(u_k) ... output_dim次元の(縦)ベクトルを出力\n",
    "#         self.delta = (loss * softmax_prime(self.output_u)).reshape(self.output_dim)\n",
    "        \n",
    "#         # W = W - η .* (δ_k * x_j.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "#         self.weight = self.weight - self.learning_rate * np.dot(self.delta.reshape(self.output_dim,1), self.input_x.reshape(1,self.input_dim))\n",
    "#         #print(\"gradient = {}\".format(np.dot(self.delta.reshape(self.output_dim,1), self.input_x.reshape(1,self.input_dim))))\n",
    "        \n",
    "#         #  δ_j = (W_kj.T *  δ_k) .* f'(u_j) ... input_dim次元の(縦)ベクトル\n",
    "#         return ( np.dot(self.weight.T, self.delta) * sigmoid_prime(self.input_u) ).reshape(self.input_dim)\n",
    "# #################################################################################################\n",
    "\n",
    "######################################最初の層についてのクラス###########################################\n",
    "class start_layer(object):\n",
    "    # initation\n",
    "    def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "        self.input_dim = input_dim # 入力次元\n",
    "        self.output_dim = output_dim #出力次元\n",
    "        self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "        self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float32) #重みを決定\n",
    "        self.bias = np.zeros((1, output_dim), dtype=np.float32) #バイアス項\n",
    "        \n",
    "    # 順伝播\n",
    "    def forward(self,x):\n",
    "        # x_h ... input_dim次元の(縦)ベクトル\n",
    "        self.input_x = np.array(x).reshape(self.input_dim)\n",
    "        \n",
    "        # u_i ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim) \n",
    "        \n",
    "        # x_i ... output_dim次元の(縦)ベクトルを出力 (sigmoidを作用させる)\n",
    "        self.output_x = sigmoid(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "        # u_i が 出力\n",
    "        return self.output_u\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self,delta):# delta = δ_i\n",
    "        # W = W - η .* (δ_i * x_h.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "        self.weight = self.weight - self.learning_rate * np.dot(delta.reshape(self.output_dim,1), self.input_x.reshape(1, self.input_dim))\n",
    "        return\n",
    " #################################################################################################\n",
    "\n",
    "\n",
    "######################################  中間層についてのクラス  ###########################################\n",
    "class mid_layer(object):\n",
    "    # initation\n",
    "    def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "        self.input_dim = input_dim # 入力次元\n",
    "        self.output_dim = output_dim #出力次元\n",
    "        self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "        self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float32) #重みを決定\n",
    "        self.bias = np.zeros((1, output_dim), dtype=np.float32) #バイアス項\n",
    "        \n",
    "    # 順伝播   \n",
    "    def forward(self,u):# u = u_i\n",
    "        \n",
    "        # u_i ... input_dim次元の(縦)ベクトル\n",
    "        self.input_u = np.array(u).reshape(self.input_dim)\n",
    "        \n",
    "        # x_i ... input_dim次元の(縦)ベクトル\n",
    "        self.input_x = sigmoid(self.input_u).reshape(self.input_dim) \n",
    "        \n",
    "        # u_j ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim)\n",
    "        \n",
    "        # x_j ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.output_x = sigmoid(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "        # u_j が 出力\n",
    "        return self.output_u\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self, delta):# delta = δ_j\n",
    "        \n",
    "        # W = W - η .* (δ_j * x_i.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "        self.weight = self.weight - self.learning_rate * np.dot(delta.reshape(self.output_dim,1), self.input_x.reshape(1, self.input_dim))\n",
    "        \n",
    "        # δ_i = (W_ji.T *  δ_j) .* f'(u_i) ... input_dim次元の(縦)ベクトル\n",
    "        return (np.dot(self.weight.T, delta) * sigmoid_prime(self.input_u)).reshape(self.input_dim)\n",
    "#################################################################################################\n",
    "\n",
    "    \n",
    "######################################  中間層についてのクラス  ###########################################    \n",
    "class last_layer(object):\n",
    "    \n",
    "    def  __init__(self, input_dim, output_dim, learning_rate=0.03):\n",
    "        self.input_dim = input_dim # 入力次元\n",
    "        self.output_dim = output_dim#出力次元\n",
    "        self.learning_rate = learning_rate #学習率(0.005 ~ 0.1)\n",
    "        self.weight = np.random.normal(np.sqrt(1.0/input_dim), size=(output_dim, input_dim)).astype(np.float32) #重みを決定\n",
    "        self.bias = np.zeros((1, output_dim), dtype=np.float32) #バイアス項\n",
    "        \n",
    "    # 順伝播    \n",
    "    def forward(self,u):# u = u_j\n",
    "        \n",
    "        # u_j ... input_dim次元の(縦)ベクトル\n",
    "        self.input_u = np.array(u).reshape(self.input_dim) \n",
    "        \n",
    "        # x_j ... input_dim次元の(縦)ベクトル\n",
    "        self.input_x = sigmoid(self.input_u).reshape(self.input_dim)\n",
    "        \n",
    "        # u_k ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.output_u = (np.dot(self.weight, self.input_x)).reshape(self.output_dim)\n",
    "        \n",
    "        # x_k ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.output_x = sigmoid(self.output_u).reshape(self.output_dim)\n",
    "        \n",
    "        # x_k が最終結果\n",
    "        return self.output_x\n",
    "    \n",
    "    # 逆伝播\n",
    "    def backward(self,loss):# loss = y - y^p\n",
    "        \n",
    "        # δ_k = loss * f'(u_k) ... output_dim次元の(縦)ベクトルを出力\n",
    "        self.delta = (loss * sigmoid_prime(self.output_u)).reshape(self.output_dim)\n",
    "        \n",
    "        # W = W - η .* (δ_k * x_j.T) ... (output_dim　×　nput_dim)次元の配列\n",
    "        self.weight = self.weight - self.learning_rate * np.dot(self.delta.reshape(self.output_dim,1), self.input_x.reshape(1,self.input_dim))\n",
    "        #print(\"gradient = {}\".format(np.dot(self.delta.reshape(self.output_dim,1), self.input_x.reshape(1,self.input_dim))))\n",
    "        \n",
    "        #  δ_j = (W_kj.T *  δ_k) .* f'(u_j) ... input_dim次元の(縦)ベクトル\n",
    "        return ( np.dot(self.weight.T, self.delta) * sigmoid_prime(self.input_u) ).reshape(self.input_dim)\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5MACUh9_ICW"
   },
   "source": [
    "## 3層用ニューラルネットの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1608180227119,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "0fvWDFjR_ICW"
   },
   "outputs": [],
   "source": [
    "def nn_3(first_layer=90, second_layer=60, third_layer=1, learning_rate=0.01, epoch_number=500, train_number=500, test_number = 100):\n",
    "    lay_1 = start_layer(first_layer, second_layer, learning_rate)\n",
    "    lay_2 = last_layer(second_layer, third_layer, learning_rate)\n",
    "\n",
    "    np.set_printoptions(precision=3)\n",
    "    accuracy_list = []\n",
    "    epoch_list = []\n",
    "    loop = 0\n",
    "    epoch_number = epoch_number#200\n",
    "    train_number = train_number#500\n",
    "    test_number = test_number#100\n",
    "\n",
    "    for epoch in range(0,epoch_number): \n",
    "        for i in range(0,train_number):\n",
    "            random_train_index = random.randint(0,training_acc.shape[0]-1)\n",
    "            #順伝播\n",
    "            output = lay_1.forward(training_acc[random_train_index].reshape(first_layer))\n",
    "            output = lay_2.forward(output)\n",
    "\n",
    "            #逆伝播\n",
    "            correct_answer = training_dis[random_train_index]\n",
    "            loss = output - correct_answer/5\n",
    "            delta = lay_2.backward(loss)\n",
    "            delta = lay_1.backward(delta)\n",
    "\n",
    "        #テストデータで正答率をチェック\n",
    "        count = 0\n",
    "        for j in range(0,test_number):\n",
    "            random_test_index = random.randint(0,training_acc.shape[0]-1)\n",
    "            output = lay_1.forward(training_acc[random_test_index].reshape(first_layer))\n",
    "            output = lay_2.forward(output)\n",
    "    \n",
    "            #print(\"output = {}\".format(output))\n",
    "            #print(\"prediction = {} <---> test_labels = {}.\".format(np.argmax(output), test_labels[random_test_index]))\n",
    "\n",
    "            count += float(training_dis[random_test_index] - 5 * output)\n",
    "\n",
    "        loop += 1\n",
    "        #print(\"#\",end=\"\")\n",
    "        print(\"\\t{:2.0f} / {} finished.  accuracy = {:2.5f}\".format(loop, epoch_number, count/test_number))\n",
    "        epoch_list.append(epoch)\n",
    "        accuracy_list.append(count/test_number)\n",
    "\n",
    "    print(\"\\t finished\")\n",
    "    return epoch_list, accuracy_list, lay_1, lay_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10428,
     "status": "ok",
     "timestamp": 1608180238001,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "Vn8E3oAK_ICX",
    "outputId": "59855490-7e56-4cc3-85ef-0181a1ebb4ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1 / 500 finished.  accuracy = -2.91959\n",
      "\t 2 / 500 finished.  accuracy = -2.85527\n",
      "\t 3 / 500 finished.  accuracy = -2.80599\n",
      "\t 4 / 500 finished.  accuracy = -2.52509\n",
      "\t 5 / 500 finished.  accuracy = -2.25889\n",
      "\t 6 / 500 finished.  accuracy = -2.50379\n",
      "\t 7 / 500 finished.  accuracy = -2.15931\n",
      "\t 8 / 500 finished.  accuracy = -1.64486\n",
      "\t 9 / 500 finished.  accuracy = -1.96095\n",
      "\t10 / 500 finished.  accuracy = -1.40562\n",
      "\t11 / 500 finished.  accuracy = -0.54334\n",
      "\t12 / 500 finished.  accuracy = -0.22811\n",
      "\t13 / 500 finished.  accuracy = 0.17761\n",
      "\t14 / 500 finished.  accuracy = 0.51769\n",
      "\t15 / 500 finished.  accuracy = 0.58522\n",
      "\t16 / 500 finished.  accuracy = 0.91357\n",
      "\t17 / 500 finished.  accuracy = 0.74317\n",
      "\t18 / 500 finished.  accuracy = 0.84312\n",
      "\t19 / 500 finished.  accuracy = 0.78079\n",
      "\t20 / 500 finished.  accuracy = 0.67628\n",
      "\t21 / 500 finished.  accuracy = 0.61305\n",
      "\t22 / 500 finished.  accuracy = 0.83462\n",
      "\t23 / 500 finished.  accuracy = 0.80302\n",
      "\t24 / 500 finished.  accuracy = 0.80729\n",
      "\t25 / 500 finished.  accuracy = 0.61387\n",
      "\t26 / 500 finished.  accuracy = 0.79105\n",
      "\t27 / 500 finished.  accuracy = 0.78823\n",
      "\t28 / 500 finished.  accuracy = 0.90223\n",
      "\t29 / 500 finished.  accuracy = 0.64189\n",
      "\t30 / 500 finished.  accuracy = 0.88925\n",
      "\t31 / 500 finished.  accuracy = 0.46179\n",
      "\t32 / 500 finished.  accuracy = 0.73206\n",
      "\t33 / 500 finished.  accuracy = 0.85159\n",
      "\t34 / 500 finished.  accuracy = 0.55321\n",
      "\t35 / 500 finished.  accuracy = 0.70890\n",
      "\t36 / 500 finished.  accuracy = 0.51744\n",
      "\t37 / 500 finished.  accuracy = 0.65831\n",
      "\t38 / 500 finished.  accuracy = 0.45153\n",
      "\t39 / 500 finished.  accuracy = 0.57868\n",
      "\t40 / 500 finished.  accuracy = 0.52417\n",
      "\t41 / 500 finished.  accuracy = 0.34726\n",
      "\t42 / 500 finished.  accuracy = 0.44359\n",
      "\t43 / 500 finished.  accuracy = 0.52497\n",
      "\t44 / 500 finished.  accuracy = 0.67597\n",
      "\t45 / 500 finished.  accuracy = 0.83084\n",
      "\t46 / 500 finished.  accuracy = 0.07164\n",
      "\t47 / 500 finished.  accuracy = 0.48888\n",
      "\t48 / 500 finished.  accuracy = 0.49935\n",
      "\t49 / 500 finished.  accuracy = 0.63047\n",
      "\t50 / 500 finished.  accuracy = 0.66599\n",
      "\t51 / 500 finished.  accuracy = 0.67041\n",
      "\t52 / 500 finished.  accuracy = 0.57366\n",
      "\t53 / 500 finished.  accuracy = 0.69304\n",
      "\t54 / 500 finished.  accuracy = 0.91577\n",
      "\t55 / 500 finished.  accuracy = 0.47499\n",
      "\t56 / 500 finished.  accuracy = 0.44138\n",
      "\t57 / 500 finished.  accuracy = 0.48295\n",
      "\t58 / 500 finished.  accuracy = 0.37188\n",
      "\t59 / 500 finished.  accuracy = 0.56212\n",
      "\t60 / 500 finished.  accuracy = 0.45037\n",
      "\t61 / 500 finished.  accuracy = 0.47476\n",
      "\t62 / 500 finished.  accuracy = 0.60931\n",
      "\t63 / 500 finished.  accuracy = 0.38802\n",
      "\t64 / 500 finished.  accuracy = 0.62613\n",
      "\t65 / 500 finished.  accuracy = 0.33381\n",
      "\t66 / 500 finished.  accuracy = 0.33325\n",
      "\t67 / 500 finished.  accuracy = 0.26458\n",
      "\t68 / 500 finished.  accuracy = 0.52415\n",
      "\t69 / 500 finished.  accuracy = 0.42485\n",
      "\t70 / 500 finished.  accuracy = 0.51874\n",
      "\t71 / 500 finished.  accuracy = 0.46129\n",
      "\t72 / 500 finished.  accuracy = 0.52778\n",
      "\t73 / 500 finished.  accuracy = 0.32696\n",
      "\t74 / 500 finished.  accuracy = 0.30236\n",
      "\t75 / 500 finished.  accuracy = 0.33095\n",
      "\t76 / 500 finished.  accuracy = 0.56696\n",
      "\t77 / 500 finished.  accuracy = 0.34071\n",
      "\t78 / 500 finished.  accuracy = 0.39845\n",
      "\t79 / 500 finished.  accuracy = 0.52424\n",
      "\t80 / 500 finished.  accuracy = 0.32490\n",
      "\t81 / 500 finished.  accuracy = 0.18180\n",
      "\t82 / 500 finished.  accuracy = 0.32581\n",
      "\t83 / 500 finished.  accuracy = 0.21656\n",
      "\t84 / 500 finished.  accuracy = 0.47083\n",
      "\t85 / 500 finished.  accuracy = 0.47715\n",
      "\t86 / 500 finished.  accuracy = 0.35473\n",
      "\t87 / 500 finished.  accuracy = 0.50010\n",
      "\t88 / 500 finished.  accuracy = 0.59502\n",
      "\t89 / 500 finished.  accuracy = 0.25719\n",
      "\t90 / 500 finished.  accuracy = 0.23473\n",
      "\t91 / 500 finished.  accuracy = 0.38871\n",
      "\t92 / 500 finished.  accuracy = 0.26992\n",
      "\t93 / 500 finished.  accuracy = 0.30669\n",
      "\t94 / 500 finished.  accuracy = 0.22138\n",
      "\t95 / 500 finished.  accuracy = 0.53277\n",
      "\t96 / 500 finished.  accuracy = 0.28092\n",
      "\t97 / 500 finished.  accuracy = 0.41040\n",
      "\t98 / 500 finished.  accuracy = 0.37405\n",
      "\t99 / 500 finished.  accuracy = 0.48384\n",
      "\t100 / 500 finished.  accuracy = 0.22555\n",
      "\t101 / 500 finished.  accuracy = 0.38317\n",
      "\t102 / 500 finished.  accuracy = 0.47451\n",
      "\t103 / 500 finished.  accuracy = 0.26599\n",
      "\t104 / 500 finished.  accuracy = 0.54664\n",
      "\t105 / 500 finished.  accuracy = 0.50216\n",
      "\t106 / 500 finished.  accuracy = 0.18550\n",
      "\t107 / 500 finished.  accuracy = 0.41499\n",
      "\t108 / 500 finished.  accuracy = 0.21903\n",
      "\t109 / 500 finished.  accuracy = 0.28152\n",
      "\t110 / 500 finished.  accuracy = 0.26813\n",
      "\t111 / 500 finished.  accuracy = 0.42893\n",
      "\t112 / 500 finished.  accuracy = 0.50578\n",
      "\t113 / 500 finished.  accuracy = 0.42362\n",
      "\t114 / 500 finished.  accuracy = 0.32190\n",
      "\t115 / 500 finished.  accuracy = 0.24604\n",
      "\t116 / 500 finished.  accuracy = 0.16114\n",
      "\t117 / 500 finished.  accuracy = 0.38927\n",
      "\t118 / 500 finished.  accuracy = 0.18900\n",
      "\t119 / 500 finished.  accuracy = 0.42860\n",
      "\t120 / 500 finished.  accuracy = 0.31936\n",
      "\t121 / 500 finished.  accuracy = 0.23780\n",
      "\t122 / 500 finished.  accuracy = 0.17288\n",
      "\t123 / 500 finished.  accuracy = 0.30032\n",
      "\t124 / 500 finished.  accuracy = 0.43074\n",
      "\t125 / 500 finished.  accuracy = 0.15296\n",
      "\t126 / 500 finished.  accuracy = 0.07389\n",
      "\t127 / 500 finished.  accuracy = 0.35297\n",
      "\t128 / 500 finished.  accuracy = 0.28745\n",
      "\t129 / 500 finished.  accuracy = 0.23171\n",
      "\t130 / 500 finished.  accuracy = 0.20785\n",
      "\t131 / 500 finished.  accuracy = 0.06100\n",
      "\t132 / 500 finished.  accuracy = 0.27798\n",
      "\t133 / 500 finished.  accuracy = 0.26300\n",
      "\t134 / 500 finished.  accuracy = 0.38487\n",
      "\t135 / 500 finished.  accuracy = 0.25561\n",
      "\t136 / 500 finished.  accuracy = 0.26878\n",
      "\t137 / 500 finished.  accuracy = 0.12200\n",
      "\t138 / 500 finished.  accuracy = 0.10909\n",
      "\t139 / 500 finished.  accuracy = 0.33257\n",
      "\t140 / 500 finished.  accuracy = 0.22205\n",
      "\t141 / 500 finished.  accuracy = 0.04838\n",
      "\t142 / 500 finished.  accuracy = 0.10375\n",
      "\t143 / 500 finished.  accuracy = 0.18680\n",
      "\t144 / 500 finished.  accuracy = 0.16311\n",
      "\t145 / 500 finished.  accuracy = 0.19561\n",
      "\t146 / 500 finished.  accuracy = 0.25497\n",
      "\t147 / 500 finished.  accuracy = 0.29236\n",
      "\t148 / 500 finished.  accuracy = 0.16271\n",
      "\t149 / 500 finished.  accuracy = 0.10912\n",
      "\t150 / 500 finished.  accuracy = 0.27467\n",
      "\t151 / 500 finished.  accuracy = 0.10112\n",
      "\t152 / 500 finished.  accuracy = 0.29699\n",
      "\t153 / 500 finished.  accuracy = 0.11900\n",
      "\t154 / 500 finished.  accuracy = 0.17013\n",
      "\t155 / 500 finished.  accuracy = 0.15163\n",
      "\t156 / 500 finished.  accuracy = 0.26142\n",
      "\t157 / 500 finished.  accuracy = 0.28808\n",
      "\t158 / 500 finished.  accuracy = 0.01920\n",
      "\t159 / 500 finished.  accuracy = 0.26764\n",
      "\t160 / 500 finished.  accuracy = -0.04151\n",
      "\t161 / 500 finished.  accuracy = 0.07527\n",
      "\t162 / 500 finished.  accuracy = 0.29445\n",
      "\t163 / 500 finished.  accuracy = 0.03830\n",
      "\t164 / 500 finished.  accuracy = 0.14980\n",
      "\t165 / 500 finished.  accuracy = 0.06807\n",
      "\t166 / 500 finished.  accuracy = 0.25608\n",
      "\t167 / 500 finished.  accuracy = 0.24907\n",
      "\t168 / 500 finished.  accuracy = 0.18485\n",
      "\t169 / 500 finished.  accuracy = -0.05845\n",
      "\t170 / 500 finished.  accuracy = 0.33587\n",
      "\t171 / 500 finished.  accuracy = -0.08911\n",
      "\t172 / 500 finished.  accuracy = 0.07277\n",
      "\t173 / 500 finished.  accuracy = -0.00726\n",
      "\t174 / 500 finished.  accuracy = 0.20288\n",
      "\t175 / 500 finished.  accuracy = 0.09519\n",
      "\t176 / 500 finished.  accuracy = 0.17158\n",
      "\t177 / 500 finished.  accuracy = 0.05974\n",
      "\t178 / 500 finished.  accuracy = -0.01219\n",
      "\t179 / 500 finished.  accuracy = 0.15821\n",
      "\t180 / 500 finished.  accuracy = 0.21755\n",
      "\t181 / 500 finished.  accuracy = 0.08586\n",
      "\t182 / 500 finished.  accuracy = 0.05737\n",
      "\t183 / 500 finished.  accuracy = 0.13619\n",
      "\t184 / 500 finished.  accuracy = 0.03815\n",
      "\t185 / 500 finished.  accuracy = 0.21234\n",
      "\t186 / 500 finished.  accuracy = 0.11470\n",
      "\t187 / 500 finished.  accuracy = 0.13073\n",
      "\t188 / 500 finished.  accuracy = 0.23962\n",
      "\t189 / 500 finished.  accuracy = 0.17861\n",
      "\t190 / 500 finished.  accuracy = 0.30669\n",
      "\t191 / 500 finished.  accuracy = 0.23839\n",
      "\t192 / 500 finished.  accuracy = 0.18351\n",
      "\t193 / 500 finished.  accuracy = 0.15237\n",
      "\t194 / 500 finished.  accuracy = 0.08925\n",
      "\t195 / 500 finished.  accuracy = 0.18713\n",
      "\t196 / 500 finished.  accuracy = 0.09968\n",
      "\t197 / 500 finished.  accuracy = 0.38006\n",
      "\t198 / 500 finished.  accuracy = 0.14561\n",
      "\t199 / 500 finished.  accuracy = 0.13916\n",
      "\t200 / 500 finished.  accuracy = 0.09756\n",
      "\t201 / 500 finished.  accuracy = 0.11611\n",
      "\t202 / 500 finished.  accuracy = 0.04018\n",
      "\t203 / 500 finished.  accuracy = 0.10630\n",
      "\t204 / 500 finished.  accuracy = 0.11551\n",
      "\t205 / 500 finished.  accuracy = 0.00860\n",
      "\t206 / 500 finished.  accuracy = -0.00419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t207 / 500 finished.  accuracy = 0.14088\n",
      "\t208 / 500 finished.  accuracy = 0.03531\n",
      "\t209 / 500 finished.  accuracy = 0.05252\n",
      "\t210 / 500 finished.  accuracy = 0.21948\n",
      "\t211 / 500 finished.  accuracy = 0.10122\n",
      "\t212 / 500 finished.  accuracy = 0.26305\n",
      "\t213 / 500 finished.  accuracy = 0.04080\n",
      "\t214 / 500 finished.  accuracy = -0.00256\n",
      "\t215 / 500 finished.  accuracy = 0.28616\n",
      "\t216 / 500 finished.  accuracy = 0.23317\n",
      "\t217 / 500 finished.  accuracy = 0.27193\n",
      "\t218 / 500 finished.  accuracy = 0.13512\n",
      "\t219 / 500 finished.  accuracy = -0.00482\n",
      "\t220 / 500 finished.  accuracy = 0.17274\n",
      "\t221 / 500 finished.  accuracy = 0.09005\n",
      "\t222 / 500 finished.  accuracy = -0.02116\n",
      "\t223 / 500 finished.  accuracy = 0.20464\n",
      "\t224 / 500 finished.  accuracy = 0.11403\n",
      "\t225 / 500 finished.  accuracy = 0.13509\n",
      "\t226 / 500 finished.  accuracy = 0.13471\n",
      "\t227 / 500 finished.  accuracy = 0.08953\n",
      "\t228 / 500 finished.  accuracy = 0.04094\n",
      "\t229 / 500 finished.  accuracy = -0.03765\n",
      "\t230 / 500 finished.  accuracy = 0.03938\n",
      "\t231 / 500 finished.  accuracy = 0.19242\n",
      "\t232 / 500 finished.  accuracy = 0.08595\n",
      "\t233 / 500 finished.  accuracy = 0.06771\n",
      "\t234 / 500 finished.  accuracy = 0.11677\n",
      "\t235 / 500 finished.  accuracy = 0.02127\n",
      "\t236 / 500 finished.  accuracy = 0.25198\n",
      "\t237 / 500 finished.  accuracy = 0.23472\n",
      "\t238 / 500 finished.  accuracy = 0.04506\n",
      "\t239 / 500 finished.  accuracy = 0.21924\n",
      "\t240 / 500 finished.  accuracy = 0.07055\n",
      "\t241 / 500 finished.  accuracy = -0.16951\n",
      "\t242 / 500 finished.  accuracy = -0.02203\n",
      "\t243 / 500 finished.  accuracy = 0.30334\n",
      "\t244 / 500 finished.  accuracy = 0.08296\n",
      "\t245 / 500 finished.  accuracy = -0.01030\n",
      "\t246 / 500 finished.  accuracy = 0.24287\n",
      "\t247 / 500 finished.  accuracy = 0.02490\n",
      "\t248 / 500 finished.  accuracy = 0.04073\n",
      "\t249 / 500 finished.  accuracy = 0.07572\n",
      "\t250 / 500 finished.  accuracy = 0.04741\n",
      "\t251 / 500 finished.  accuracy = 0.13830\n",
      "\t252 / 500 finished.  accuracy = 0.09478\n",
      "\t253 / 500 finished.  accuracy = 0.12945\n",
      "\t254 / 500 finished.  accuracy = 0.10390\n",
      "\t255 / 500 finished.  accuracy = 0.14769\n",
      "\t256 / 500 finished.  accuracy = 0.03177\n",
      "\t257 / 500 finished.  accuracy = 0.03535\n",
      "\t258 / 500 finished.  accuracy = 0.10806\n",
      "\t259 / 500 finished.  accuracy = 0.00597\n",
      "\t260 / 500 finished.  accuracy = 0.10689\n",
      "\t261 / 500 finished.  accuracy = 0.11285\n",
      "\t262 / 500 finished.  accuracy = 0.07262\n",
      "\t263 / 500 finished.  accuracy = -0.04507\n",
      "\t264 / 500 finished.  accuracy = 0.04713\n",
      "\t265 / 500 finished.  accuracy = -0.12145\n",
      "\t266 / 500 finished.  accuracy = 0.02145\n",
      "\t267 / 500 finished.  accuracy = 0.03906\n",
      "\t268 / 500 finished.  accuracy = 0.07558\n",
      "\t269 / 500 finished.  accuracy = 0.05756\n",
      "\t270 / 500 finished.  accuracy = 0.20544\n",
      "\t271 / 500 finished.  accuracy = 0.08632\n",
      "\t272 / 500 finished.  accuracy = 0.15911\n",
      "\t273 / 500 finished.  accuracy = 0.00271\n",
      "\t274 / 500 finished.  accuracy = -0.08914\n",
      "\t275 / 500 finished.  accuracy = 0.04034\n",
      "\t276 / 500 finished.  accuracy = 0.10503\n",
      "\t277 / 500 finished.  accuracy = -0.01935\n",
      "\t278 / 500 finished.  accuracy = -0.08596\n",
      "\t279 / 500 finished.  accuracy = 0.09032\n",
      "\t280 / 500 finished.  accuracy = 0.07285\n",
      "\t281 / 500 finished.  accuracy = 0.04224\n",
      "\t282 / 500 finished.  accuracy = -0.00654\n",
      "\t283 / 500 finished.  accuracy = 0.06097\n",
      "\t284 / 500 finished.  accuracy = 0.10030\n",
      "\t285 / 500 finished.  accuracy = -0.04971\n",
      "\t286 / 500 finished.  accuracy = 0.05714\n",
      "\t287 / 500 finished.  accuracy = 0.06568\n",
      "\t288 / 500 finished.  accuracy = 0.07747\n",
      "\t289 / 500 finished.  accuracy = -0.08350\n",
      "\t290 / 500 finished.  accuracy = -0.15776\n",
      "\t291 / 500 finished.  accuracy = 0.07837\n",
      "\t292 / 500 finished.  accuracy = 0.03702\n",
      "\t293 / 500 finished.  accuracy = -0.03644\n",
      "\t294 / 500 finished.  accuracy = 0.08003\n",
      "\t295 / 500 finished.  accuracy = 0.10330\n",
      "\t296 / 500 finished.  accuracy = 0.05752\n",
      "\t297 / 500 finished.  accuracy = 0.11808\n",
      "\t298 / 500 finished.  accuracy = 0.04391\n",
      "\t299 / 500 finished.  accuracy = 0.08732\n",
      "\t300 / 500 finished.  accuracy = 0.01665\n",
      "\t301 / 500 finished.  accuracy = -0.01588\n",
      "\t302 / 500 finished.  accuracy = 0.03241\n",
      "\t303 / 500 finished.  accuracy = -0.06243\n",
      "\t304 / 500 finished.  accuracy = -0.04596\n",
      "\t305 / 500 finished.  accuracy = 0.06421\n",
      "\t306 / 500 finished.  accuracy = 0.18054\n",
      "\t307 / 500 finished.  accuracy = 0.00729\n",
      "\t308 / 500 finished.  accuracy = -0.01221\n",
      "\t309 / 500 finished.  accuracy = -0.00104\n",
      "\t310 / 500 finished.  accuracy = -0.09366\n",
      "\t311 / 500 finished.  accuracy = 0.03515\n",
      "\t312 / 500 finished.  accuracy = 0.09767\n",
      "\t313 / 500 finished.  accuracy = 0.03850\n",
      "\t314 / 500 finished.  accuracy = 0.01062\n",
      "\t315 / 500 finished.  accuracy = 0.03129\n",
      "\t316 / 500 finished.  accuracy = 0.02821\n",
      "\t317 / 500 finished.  accuracy = 0.05488\n",
      "\t318 / 500 finished.  accuracy = -0.01623\n",
      "\t319 / 500 finished.  accuracy = -0.00890\n",
      "\t320 / 500 finished.  accuracy = 0.10968\n",
      "\t321 / 500 finished.  accuracy = -0.03701\n",
      "\t322 / 500 finished.  accuracy = 0.08031\n",
      "\t323 / 500 finished.  accuracy = -0.05743\n",
      "\t324 / 500 finished.  accuracy = 0.02825\n",
      "\t325 / 500 finished.  accuracy = 0.00276\n",
      "\t326 / 500 finished.  accuracy = -0.01057\n",
      "\t327 / 500 finished.  accuracy = 0.13046\n",
      "\t328 / 500 finished.  accuracy = 0.08059\n",
      "\t329 / 500 finished.  accuracy = 0.10809\n",
      "\t330 / 500 finished.  accuracy = 0.03024\n",
      "\t331 / 500 finished.  accuracy = 0.10371\n",
      "\t332 / 500 finished.  accuracy = 0.03298\n",
      "\t333 / 500 finished.  accuracy = 0.04620\n",
      "\t334 / 500 finished.  accuracy = 0.01546\n",
      "\t335 / 500 finished.  accuracy = 0.07511\n",
      "\t336 / 500 finished.  accuracy = 0.07796\n",
      "\t337 / 500 finished.  accuracy = 0.03317\n",
      "\t338 / 500 finished.  accuracy = -0.08581\n",
      "\t339 / 500 finished.  accuracy = -0.04273\n",
      "\t340 / 500 finished.  accuracy = 0.00234\n",
      "\t341 / 500 finished.  accuracy = 0.02631\n",
      "\t342 / 500 finished.  accuracy = 0.05668\n",
      "\t343 / 500 finished.  accuracy = -0.00339\n",
      "\t344 / 500 finished.  accuracy = -0.00993\n",
      "\t345 / 500 finished.  accuracy = -0.07994\n",
      "\t346 / 500 finished.  accuracy = 0.09891\n",
      "\t347 / 500 finished.  accuracy = 0.07901\n",
      "\t348 / 500 finished.  accuracy = -0.05496\n",
      "\t349 / 500 finished.  accuracy = 0.05549\n",
      "\t350 / 500 finished.  accuracy = -0.13691\n",
      "\t351 / 500 finished.  accuracy = 0.08836\n",
      "\t352 / 500 finished.  accuracy = -0.11489\n",
      "\t353 / 500 finished.  accuracy = -0.13743\n",
      "\t354 / 500 finished.  accuracy = 0.06082\n",
      "\t355 / 500 finished.  accuracy = 0.02891\n",
      "\t356 / 500 finished.  accuracy = -0.01509\n",
      "\t357 / 500 finished.  accuracy = -0.01442\n",
      "\t358 / 500 finished.  accuracy = 0.10698\n",
      "\t359 / 500 finished.  accuracy = 0.08690\n",
      "\t360 / 500 finished.  accuracy = -0.04412\n",
      "\t361 / 500 finished.  accuracy = -0.00622\n",
      "\t362 / 500 finished.  accuracy = 0.04435\n",
      "\t363 / 500 finished.  accuracy = -0.10448\n",
      "\t364 / 500 finished.  accuracy = 0.03486\n",
      "\t365 / 500 finished.  accuracy = 0.17826\n",
      "\t366 / 500 finished.  accuracy = 0.02427\n",
      "\t367 / 500 finished.  accuracy = -0.19346\n",
      "\t368 / 500 finished.  accuracy = 0.11958\n",
      "\t369 / 500 finished.  accuracy = -0.02864\n",
      "\t370 / 500 finished.  accuracy = 0.04284\n",
      "\t371 / 500 finished.  accuracy = 0.10807\n",
      "\t372 / 500 finished.  accuracy = -0.03395\n",
      "\t373 / 500 finished.  accuracy = 0.03241\n",
      "\t374 / 500 finished.  accuracy = 0.00227\n",
      "\t375 / 500 finished.  accuracy = -0.06125\n",
      "\t376 / 500 finished.  accuracy = -0.01826\n",
      "\t377 / 500 finished.  accuracy = 0.00441\n",
      "\t378 / 500 finished.  accuracy = 0.08970\n",
      "\t379 / 500 finished.  accuracy = 0.01773\n",
      "\t380 / 500 finished.  accuracy = -0.00264\n",
      "\t381 / 500 finished.  accuracy = 0.07114\n",
      "\t382 / 500 finished.  accuracy = 0.09658\n",
      "\t383 / 500 finished.  accuracy = -0.01011\n",
      "\t384 / 500 finished.  accuracy = 0.17940\n",
      "\t385 / 500 finished.  accuracy = 0.07967\n",
      "\t386 / 500 finished.  accuracy = 0.04087\n",
      "\t387 / 500 finished.  accuracy = 0.07186\n",
      "\t388 / 500 finished.  accuracy = -0.00749\n",
      "\t389 / 500 finished.  accuracy = -0.06402\n",
      "\t390 / 500 finished.  accuracy = -0.11290\n",
      "\t391 / 500 finished.  accuracy = -0.04539\n",
      "\t392 / 500 finished.  accuracy = -0.03871\n",
      "\t393 / 500 finished.  accuracy = -0.02662\n",
      "\t394 / 500 finished.  accuracy = -0.02036\n",
      "\t395 / 500 finished.  accuracy = 0.02758\n",
      "\t396 / 500 finished.  accuracy = -0.00734\n",
      "\t397 / 500 finished.  accuracy = 0.04453\n",
      "\t398 / 500 finished.  accuracy = 0.15342\n",
      "\t399 / 500 finished.  accuracy = -0.02797\n",
      "\t400 / 500 finished.  accuracy = -0.02323\n",
      "\t401 / 500 finished.  accuracy = 0.11684\n",
      "\t402 / 500 finished.  accuracy = 0.04621\n",
      "\t403 / 500 finished.  accuracy = -0.03772\n",
      "\t404 / 500 finished.  accuracy = -0.02940\n",
      "\t405 / 500 finished.  accuracy = 0.03958\n",
      "\t406 / 500 finished.  accuracy = 0.00325\n",
      "\t407 / 500 finished.  accuracy = 0.00539\n",
      "\t408 / 500 finished.  accuracy = 0.02796\n",
      "\t409 / 500 finished.  accuracy = 0.05400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t410 / 500 finished.  accuracy = -0.00472\n",
      "\t411 / 500 finished.  accuracy = -0.00237\n",
      "\t412 / 500 finished.  accuracy = -0.05481\n",
      "\t413 / 500 finished.  accuracy = 0.00570\n",
      "\t414 / 500 finished.  accuracy = -0.08568\n",
      "\t415 / 500 finished.  accuracy = -0.06170\n",
      "\t416 / 500 finished.  accuracy = 0.01490\n",
      "\t417 / 500 finished.  accuracy = -0.02668\n",
      "\t418 / 500 finished.  accuracy = -0.06617\n",
      "\t419 / 500 finished.  accuracy = -0.03774\n",
      "\t420 / 500 finished.  accuracy = 0.09446\n",
      "\t421 / 500 finished.  accuracy = -0.01206\n",
      "\t422 / 500 finished.  accuracy = -0.05029\n",
      "\t423 / 500 finished.  accuracy = -0.01723\n",
      "\t424 / 500 finished.  accuracy = -0.08348\n",
      "\t425 / 500 finished.  accuracy = -0.01652\n",
      "\t426 / 500 finished.  accuracy = 0.02395\n",
      "\t427 / 500 finished.  accuracy = 0.02009\n",
      "\t428 / 500 finished.  accuracy = -0.03668\n",
      "\t429 / 500 finished.  accuracy = 0.10520\n",
      "\t430 / 500 finished.  accuracy = 0.04616\n",
      "\t431 / 500 finished.  accuracy = -0.04664\n",
      "\t432 / 500 finished.  accuracy = -0.18063\n",
      "\t433 / 500 finished.  accuracy = 0.01775\n",
      "\t434 / 500 finished.  accuracy = -0.07711\n",
      "\t435 / 500 finished.  accuracy = -0.01718\n",
      "\t436 / 500 finished.  accuracy = -0.00153\n",
      "\t437 / 500 finished.  accuracy = -0.09555\n",
      "\t438 / 500 finished.  accuracy = -0.03530\n",
      "\t439 / 500 finished.  accuracy = 0.02142\n",
      "\t440 / 500 finished.  accuracy = 0.00379\n",
      "\t441 / 500 finished.  accuracy = -0.02416\n",
      "\t442 / 500 finished.  accuracy = -0.09173\n",
      "\t443 / 500 finished.  accuracy = 0.02411\n",
      "\t444 / 500 finished.  accuracy = 0.07488\n",
      "\t445 / 500 finished.  accuracy = 0.14844\n",
      "\t446 / 500 finished.  accuracy = 0.11330\n",
      "\t447 / 500 finished.  accuracy = -0.04144\n",
      "\t448 / 500 finished.  accuracy = 0.07024\n",
      "\t449 / 500 finished.  accuracy = -0.03137\n",
      "\t450 / 500 finished.  accuracy = 0.07581\n",
      "\t451 / 500 finished.  accuracy = -0.04817\n",
      "\t452 / 500 finished.  accuracy = -0.00211\n",
      "\t453 / 500 finished.  accuracy = -0.01335\n",
      "\t454 / 500 finished.  accuracy = -0.03472\n",
      "\t455 / 500 finished.  accuracy = 0.05465\n",
      "\t456 / 500 finished.  accuracy = -0.06153\n",
      "\t457 / 500 finished.  accuracy = -0.06460\n",
      "\t458 / 500 finished.  accuracy = -0.00901\n",
      "\t459 / 500 finished.  accuracy = -0.11997\n",
      "\t460 / 500 finished.  accuracy = 0.08913\n",
      "\t461 / 500 finished.  accuracy = -0.06491\n",
      "\t462 / 500 finished.  accuracy = 0.02075\n",
      "\t463 / 500 finished.  accuracy = 0.00150\n",
      "\t464 / 500 finished.  accuracy = -0.07733\n",
      "\t465 / 500 finished.  accuracy = -0.06658\n",
      "\t466 / 500 finished.  accuracy = 0.02539\n",
      "\t467 / 500 finished.  accuracy = -0.05851\n",
      "\t468 / 500 finished.  accuracy = 0.02315\n",
      "\t469 / 500 finished.  accuracy = -0.08135\n",
      "\t470 / 500 finished.  accuracy = -0.00124\n",
      "\t471 / 500 finished.  accuracy = -0.00390\n",
      "\t472 / 500 finished.  accuracy = 0.01765\n",
      "\t473 / 500 finished.  accuracy = 0.00070\n",
      "\t474 / 500 finished.  accuracy = -0.01945\n",
      "\t475 / 500 finished.  accuracy = 0.03643\n",
      "\t476 / 500 finished.  accuracy = 0.00020\n",
      "\t477 / 500 finished.  accuracy = 0.01468\n",
      "\t478 / 500 finished.  accuracy = -0.06130\n",
      "\t479 / 500 finished.  accuracy = -0.01820\n",
      "\t480 / 500 finished.  accuracy = -0.04395\n",
      "\t481 / 500 finished.  accuracy = -0.04741\n",
      "\t482 / 500 finished.  accuracy = -0.08689\n",
      "\t483 / 500 finished.  accuracy = 0.09575\n",
      "\t484 / 500 finished.  accuracy = -0.02598\n",
      "\t485 / 500 finished.  accuracy = 0.03211\n",
      "\t486 / 500 finished.  accuracy = 0.03572\n",
      "\t487 / 500 finished.  accuracy = -0.01110\n",
      "\t488 / 500 finished.  accuracy = -0.05324\n",
      "\t489 / 500 finished.  accuracy = -0.03170\n",
      "\t490 / 500 finished.  accuracy = -0.01311\n",
      "\t491 / 500 finished.  accuracy = -0.01399\n",
      "\t492 / 500 finished.  accuracy = -0.04834\n",
      "\t493 / 500 finished.  accuracy = 0.06838\n",
      "\t494 / 500 finished.  accuracy = -0.03117\n",
      "\t495 / 500 finished.  accuracy = -0.06920\n",
      "\t496 / 500 finished.  accuracy = 0.13273\n",
      "\t497 / 500 finished.  accuracy = -0.10499\n",
      "\t498 / 500 finished.  accuracy = 0.10126\n",
      "\t499 / 500 finished.  accuracy = 0.03174\n",
      "\t500 / 500 finished.  accuracy = -0.07371\n",
      "\t finished\n"
     ]
    }
   ],
   "source": [
    "epoch, step_diff, lay1, lay2= nn_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1608180240424,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "ubBDcCb6_ICX",
    "outputId": "926e529c-d606-4f3c-edee-7be421b8bc74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, step_diff,label=\"3_layer\")\n",
    "\n",
    "plt.xlabel(\"epoch time\")\n",
    "plt.ylabel(\"step_diff\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig(\"../report/5-2-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1608180252590,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "02tDvUigLe5h"
   },
   "outputs": [],
   "source": [
    "#保存\n",
    "np.savetxt(\"data/w1.txt\",lay1.weight, delimiter=' ', fmt='%f')\n",
    "np.savetxt(\"data/w2.txt\",lay2.weight, delimiter=' ', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1608180253511,
     "user": {
      "displayName": "Atsushi Narita",
      "photoUrl": "",
      "userId": "16280443261260851131"
     },
     "user_tz": -540
    },
    "id": "fpnKNqbUOBII",
    "outputId": "3b4ca84a-7927-4139-be68-b5ff2cf413b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = \n",
      " [[-1.378e+00 -1.410e+00 -1.396e+00 ... -1.113e+00  9.707e-02  5.756e-01]\n",
      " [ 9.044e-01  2.232e-02  6.374e-01 ... -5.528e-02 -3.337e-03 -1.287e+00]\n",
      " [ 2.247e-01 -4.480e-04  2.043e-01 ...  6.042e-01 -1.348e-01 -6.033e-01]\n",
      " ...\n",
      " [ 9.286e-01 -2.318e-01 -3.670e-01 ...  1.030e+00 -8.722e-02  6.839e-01]\n",
      " [-8.881e-01  3.691e-01 -4.856e-01 ... -9.008e-01  1.756e+00 -1.029e+00]\n",
      " [ 1.231e-01  2.417e+00 -3.811e-01 ...  3.347e-01  1.196e-01 -6.432e-01]]\n",
      "\n",
      "lay1.weight = \n",
      " [[-1.378e+00 -1.410e+00 -1.396e+00 ... -1.113e+00  9.707e-02  5.756e-01]\n",
      " [ 9.044e-01  2.232e-02  6.374e-01 ... -5.528e-02 -3.337e-03 -1.287e+00]\n",
      " [ 2.247e-01 -4.484e-04  2.043e-01 ...  6.042e-01 -1.349e-01 -6.033e-01]\n",
      " ...\n",
      " [ 9.286e-01 -2.318e-01 -3.670e-01 ...  1.030e+00 -8.723e-02  6.839e-01]\n",
      " [-8.881e-01  3.691e-01 -4.856e-01 ... -9.008e-01  1.756e+00 -1.029e+00]\n",
      " [ 1.231e-01  2.417e+00 -3.811e-01 ...  3.347e-01  1.196e-01 -6.432e-01]]\n",
      "\n",
      "w == lay.weight ?\n",
      " [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "\n",
      "Oh, my Gosh\n"
     ]
    }
   ],
   "source": [
    "w = np.array(np.loadtxt('data/w1.txt', dtype='float32'))\n",
    "\n",
    "print(\"w = \\n\", w)\n",
    "print(\"\\nlay1.weight = \\n\",lay1.weight)\n",
    "print(\"\\nw == lay.weight ?\\n\",w==lay1.weight)\n",
    "\n",
    "if np.all(w==lay1.weight):\n",
    "  print(\"\\nYEAH\")\n",
    "else:\n",
    "  print(\"\\nOh, my Gosh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "pAuINYD5BOlD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  0.6383301476068869\n"
     ]
    }
   ],
   "source": [
    "acc_array = np.zeros(3)\n",
    "output = lay1.forward(acc_array.reshape(3))\n",
    "output = lay2.forward(output)\n",
    "print(\"output = \",float(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "lay1 = start_layer(3,3)\n",
    "lay2 = last_layer(3,1)\n",
    "for i in range(0,10000):\n",
    "    #順伝播\n",
    "    output = lay1.forward([1,1,3])\n",
    "    output = lay2.forward(output)\n",
    "    #逆伝播\n",
    "    correct_answer = np.array([3])\n",
    "    loss = output - correct_answer/5\n",
    "    delta = lay2.backward(loss)\n",
    "    delta = lay1.backward(delta)\n",
    "output = lay1.forward([1,1,3])\n",
    "output = lay2.forward(output)\n",
    "print(output*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn_learn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
